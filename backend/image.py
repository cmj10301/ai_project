from fastapi import APIRouter, Request
from pydantic import BaseModel
from transformers import BlipProcessor, BlipForConditionalGeneration
from PIL import Image
import base64
import io
import requests

router = APIRouter()

# ëª¨ë¸ ë° í”„ë¡œì„¸ì„œ ë¡œë”© (ìµœì´ˆ 1íšŒ)
processor = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-base")
model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-base")

class ImageRequest(BaseModel):
    image: str  # base64 string

@router.post("/api/image")
async def analyze_image(req: ImageRequest):
    # base64 ë””ì½”ë”©
    header, encoded = req.image.split(",", 1)
    image = Image.open(io.BytesIO(base64.b64decode(encoded))).convert("RGB")

    # ìº¡ì…˜ ì¶”ì¶œ
    inputs = processor(images=image, return_tensors="pt")
    out = model.generate(**inputs, max_new_tokens=20)
    caption = processor.decode(out[0], skip_special_tokens=True)

    # ìœ„í‚¤ë°±ê³¼ ê²€ìƒ‰
    query = caption.split(',')[0].strip().split(' ')[-1]  # ì˜ˆì‹œ: ë§ˆì§€ë§‰ ëª…ì‚¬ ì¶”ì¶œ
    summary = fetch_wikipedia_summary(query)

    return {"caption": caption, "keyword": query, "summary": summary}

def fetch_wikipedia_summary(query: str) -> str:
    url = f"https://ko.wikipedia.org/api/rest_v1/page/summary/{query}"
    resp = requests.get(url)
    if resp.status_code == 200 and 'extract' in resp.json():
        return resp.json()['extract']
    else:
        return "ğŸ“Œ ìœ„í‚¤ë°±ê³¼ì—ì„œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
